import Foundation
import AVFoundation
import WhisperKit
import CoreGraphics
import Carbon.HIToolbox
import AppKit
import ApplicationServices
import IOKit.hid  // For low-level HID monitoring
import OSLog
import Cocoa  // For NSWorkspace

class VoiceDictationService {
    private var whisperKit: WhisperKit?
    private let audioEngine = AVAudioEngine()
    private var recognitionTask: Task<Void, Never>?
    private var isRecording = false
    private var audioBuffer = [Float]()
    private let bufferLock = NSLock()
    private let bufferQueue = DispatchQueue(label: "com.stt.audiobuffer")
    
    // Event tap for Fn key
    private var eventTap: CFMachPort?
    private var lastFlags: CGEventFlags = CGEventFlags()
    
    // IOKit HID monitoring for Fn key detection (bypasses Sequoia's event suppression)
    private var hidManager: IOHIDManager?
    private var lastModifiers: UInt32 = 0
    private var eventMonitor: Any?  // NSEvent monitor fallback
    
    // Configuration
    private let sampleRate: Double = 16000
    private let chunkDuration: Double = 2.0 // 2.0s chunks for better context
    private let modelName = "openai_whisper-large-v3-turbo"
    
    // Wispr Flow approach: Debug mode for testing
    private let debugMode = false // Set to false for production
    
    // Apple dictation sounds
    private var dictationBeginSound: NSSound?
    private var dictationConfirmSound: NSSound?
    
    init() {
        checkAccessibilityPermissions()
        setupWhisperKit()
        setupDictationSounds()
        // DON'T setup hotkey in init - wait for app launch
    }
    
    // NEW: Call this AFTER applicationDidFinishLaunching
    func initializeAfterLaunch() {
        NSLog("ğŸš€ Initializing STT after app launch...")
        
        // CRITICAL: Check TCC permissions early to force cache refresh and detect bugs
        checkAccessibilityPermissions()
        
        checkSystemSettings()
        // PERMANENTLY DISABLED hidutil remapping - causes system freeze in Sequoia
        // hidutil is deprecated and unstable in macOS 15.x - using IOKit HID instead
        setupHIDMonitor()  // Primary: IOKit low-level detection bypasses Sequoia suppression
        setupNSEventMonitor()  // Fallback: NSEvent monitoring
        setupHotkey()  // Backup: CGEventTap (for debugging)
    }
    
    private func applyHidutilRemapping() {
        NSLog("ğŸ”§ Applying hidutil Fn key remapping for Sequoia compatibility...")
        NSLog("   Remapping Fn (0x700000065) â†’ keyCode 255 (0x7000000FF)")
        
        let task = Process()
        task.launchPath = "/usr/bin/hidutil"
        task.arguments = ["property", "--set", "{\"UserKeyMapping\":[{\"HIDKeyboardModifierMappingSrc\":0x700000065,\"HIDKeyboardModifierMappingDst\":0x7000000FF}]}"]
        
        do {
            try task.run()
            task.waitUntilExit()
            if task.terminationStatus == 0 {
                NSLog("âœ… hidutil remapping applied successfully")
                NSLog("ğŸ”§ Fn key will now generate keyDown/keyUp events instead of flagsChanged")
                NSLog("ğŸ¯ This bypasses Sequoia's modifier event filtering")
            } else {
                NSLog("âš ï¸ hidutil remapping failed with status: \(task.terminationStatus)")
            }
        } catch {
            NSLog("âŒ Failed to run hidutil: \(error)")
        }
    }
    
    private func setupHIDMonitor() {
        NSLog("ğŸ”§ Setting up IOKit HID monitor for Fn key detection...")
        
        hidManager = IOHIDManagerCreate(kCFAllocatorDefault, IOOptionBits(kIOHIDOptionsTypeNone))
        guard let manager = hidManager else {
            NSLog("âŒ Failed to create IOHIDManager")
            return
        }
        
        // Match keyboard devices (usage page and usage for keyboards)
        let matchingDict: CFDictionary = [
            kIOHIDDeviceUsagePageKey: kHIDPage_GenericDesktop,
            kIOHIDDeviceUsageKey: kHIDUsage_GD_Keyboard
        ] as CFDictionary
        IOHIDManagerSetDeviceMatching(manager, matchingDict)
        
        // Register callback for input value changes (keystrokes and modifiers)
        IOHIDManagerRegisterInputValueCallback(manager, { context, result, sender, value in
            guard let context = context else { return }
            let service = Unmanaged<VoiceDictationService>.fromOpaque(context).takeUnretainedValue()
            
            let elem = IOHIDValueGetElement(value)
            let usagePage = IOHIDElementGetUsagePage(elem)
            let usage = IOHIDElementGetUsage(elem)
            let modifierValue = IOHIDValueGetIntegerValue(value)
            
            // Log all for debugging to find exact Fn usage (run once, note Fn's usage)
            NSLog("ğŸ“¥ HID event: usagePage=\(usagePage), usage=\(usage), value=\(modifierValue)")
            
            // Detect Fn: On Apple keyboards, Fn is often usage 0xFF (or kHIDUsage_KbdFN ~101 decimal) in keyboard page
            // Adjust based on your logs: Press Fn and look for unique usage (e.g., 101 or bit shift)
            if usagePage == kHIDPage_KeyboardOrKeypad && (usage == 101 || usage == 0xFF || usage == 255) {  // Common Fn usages; confirm via logs
                if modifierValue == 1 && (service.lastModifiers & (1 << usage)) == 0 {  // Press down (value 1) and not previously set
                    NSLog("ğŸ”‘ HID Fn key pressed - toggling dictation")
                    
                    // Show visual feedback immediately
                    AppDelegate.shared?.showFnKeyPressed()
                    
                    service.toggleRecording()
                }
                // Update state to detect press/release
                if modifierValue == 1 {
                    service.lastModifiers |= (1 << usage)
                } else {
                    service.lastModifiers &= ~(1 << usage)
                }
            }
        }, Unmanaged.passUnretained(self).toOpaque())
        
        // Schedule with main run loop
        IOHIDManagerScheduleWithRunLoop(manager, CFRunLoopGetMain(), CFRunLoopMode.defaultMode.rawValue)
        
        // Open the manager (requires Input Monitoring permission, already granted)
        let openResult = IOHIDManagerOpen(manager, IOOptionBits(kIOHIDOptionsTypeNone))
        if openResult != kIOReturnSuccess {
            NSLog("âŒ HID open failed: \(openResult) - Check Input Monitoring permission")
        } else {
            NSLog("âœ… HID monitor setup successful - monitoring for Fn key events")
        }
    }
    
    private func setupNSEventMonitor() {
        NSLog("ğŸ”§ Setting up NSEvent monitor as fallback for Fn key detection...")
        
        eventMonitor = NSEvent.addGlobalMonitorForEvents(matching: .flagsChanged) { event in
            if event.modifierFlags.contains(.function) {
                NSLog("ğŸ”‘ NSEvent Fn key pressed - toggling dictation")
                
                // Show visual feedback immediately
                AppDelegate.shared?.showFnKeyPressed()
                
                self.toggleRecording()
            }
        }
        
        if eventMonitor != nil {
            NSLog("âœ… NSEvent monitor setup successful")
        } else {
            NSLog("âŒ Failed to setup NSEvent monitor")
        }
    }
    
    deinit {
        // Clean up HID manager
        if let manager = hidManager {
            IOHIDManagerClose(manager, IOOptionBits(kIOHIDOptionsTypeNone))
        }
        
        // Clean up NSEvent monitor
        if let monitor = eventMonitor {
            NSEvent.removeMonitor(monitor)
        }
        
        disableFnTap()
    }
    
    private func setupWhisperKit() {
        Task {
            do {
                NSLog("ğŸ“¥ WHISPERKIT: Starting model loading...")
                print("ğŸ“¥ Loading WhisperKit model...")
                
                // Use Application Support directory instead of Documents to avoid permission prompts
                let appSupportURL = try FileManager.default.url(
                    for: .applicationSupportDirectory,
                    in: .userDomainMask,
                    appropriateFor: nil,
                    create: true
                )
                
                // Create WhisperKit subdirectory in Application Support
                let whisperKitFolder = appSupportURL.appendingPathComponent("STTDictate/WhisperKit")
                try FileManager.default.createDirectory(
                    at: whisperKitFolder,
                    withIntermediateDirectories: true,
                    attributes: nil
                )
                
                NSLog("ğŸ“ WHISPERKIT: Using model directory: \(whisperKitFolder.path)")
                print("ğŸ“ Using model directory: \(whisperKitFolder.path)")
                
                // Try to load the large-v3-turbo model (let it download to default location first)
                NSLog("ğŸ”„ WHISPERKIT: Initializing large-v3-turbo model...")
                whisperKit = try await WhisperKit(
                    model: "openai_whisper-large-v3-turbo"
                )
                NSLog("âœ… WHISPERKIT: Model loaded successfully!")
                print("âœ… WhisperKit loaded successfully")
                print("ğŸ¯ Ready! Press Fn to start/stop dictation")
            } catch {
                NSLog("âŒ WHISPERKIT: Failed to load turbo model: \(error)")
                print("âŒ Failed to load turbo model: \(error)")
                print("ğŸ”„ Falling back to default model...")
                do {
                    // Fallback to default model with Application Support
                    let appSupportURL = try FileManager.default.url(
                        for: .applicationSupportDirectory,
                        in: .userDomainMask,
                        appropriateFor: nil,
                        create: true
                    )
                    let whisperKitFolder = appSupportURL.appendingPathComponent("STTDictate/WhisperKit")
                    
                    NSLog("ğŸ”„ WHISPERKIT: Trying fallback model...")
                    whisperKit = try await WhisperKit()
                    NSLog("âœ… WHISPERKIT: Fallback model loaded successfully!")
                    print("âœ… WhisperKit fallback loaded successfully")
                } catch {
                    NSLog("âŒ WHISPERKIT: FAILED to load any model: \(error)")
                    print("âŒ Failed to load any WhisperKit model: \(error)")
                }
            }
        }
    }
    
    private func setupDictationSounds() {
        NSLog("ğŸ”Š Loading custom dictation sounds...")
        
        // Load custom dictation sounds from app bundle Resources
        if let bundle = Bundle.main.resourcePath {
            // Load begin sound (dictation_event1.wav)
            let beginSoundPath = bundle + "/dictation_event1.wav"
            if FileManager.default.fileExists(atPath: beginSoundPath) {
                dictationBeginSound = NSSound(contentsOfFile: beginSoundPath, byReference: true)
                NSLog("âœ… Loaded dictation begin sound: dictation_event1.wav")
            } else {
                NSLog("âš ï¸ Dictation begin sound not found at: \(beginSoundPath)")
            }
            
            // Load confirm sound (dictation_event2.wav)
            let confirmSoundPath = bundle + "/dictation_event2.wav"
            if FileManager.default.fileExists(atPath: confirmSoundPath) {
                dictationConfirmSound = NSSound(contentsOfFile: confirmSoundPath, byReference: true)
                NSLog("âœ… Loaded dictation confirm sound: dictation_event2.wav")
            } else {
                NSLog("âš ï¸ Dictation confirm sound not found at: \(confirmSoundPath)")
            }
        } else {
            NSLog("âŒ Could not find app bundle resource path")
        }
    }
    
    private func checkAccessibilityPermissions() {
        NSLog("ğŸ” Starting comprehensive TCC cache bug detection and remediation...")
        
        // Force prompt to invalidate cache
        let options: CFDictionary = [kAXTrustedCheckOptionPrompt.takeUnretainedValue() as String: true] as CFDictionary
        let trustedWithPrompt = AXIsProcessTrustedWithOptions(options)
        NSLog("ğŸ” AXIsProcessTrustedWithOptions result: \(trustedWithPrompt)")
        
        let trustedCached = AXIsProcessTrusted()
        NSLog("ğŸ” AXIsProcessTrusted (cached) result: \(trustedCached)")
        
        if trustedWithPrompt && !trustedCached {
            NSLog("ğŸ› DETECTED: macOS Sequoia TCC caching bug")
            handleTCCCacheBug()
            return
        }
        
        if !trustedWithPrompt && !trustedCached {
            NSLog("âŒ Accessibility permissions completely denied")
            showPermissionInstructions()
            return
        }
        
        if trustedCached {
            NSLog("âœ… Accessibility granted")
            return
        }
        
        // Edge case retry
        let _ = AXIsProcessTrustedWithOptions(options)
        let finalCheck = AXIsProcessTrusted()
        NSLog("ğŸ” Final status after retry: \(finalCheck ? "GRANTED" : "DENIED")")
        
        if !finalCheck {
            handleTCCCacheBug()
        }
    }
    
    private func handleTCCCacheBug() {
        NSLog("ğŸ”§ HANDLING SEQUOIA TCC CACHE BUG - Known issue affecting rebuilt/self-signed apps")
        NSLog("")
        NSLog("ğŸ“‹ AUTOMATED REMEDIATION STEPS:")
        NSLog("1. Attempting automated TCC reset...")
        
        // Step 1: Automated TCC reset
        let resetResult = resetTCCDatabase()
        if resetResult {
            NSLog("âœ… TCC database reset successful")
        } else {
            NSLog("âš ï¸ TCC database reset failed or not needed")
        }
        
        // Step 2: Daemon reload
        reloadSystemDaemons()
        
        // Step 3: Re-test after automated fixes
        let retestResult = AXIsProcessTrusted()
        if retestResult {
            NSLog("ğŸ‰ AUTOMATED FIX SUCCESSFUL - TCC cache bug resolved!")
            return
        }
        
        // Step 4: Manual intervention required
        NSLog("âŒ Automated fixes insufficient - manual intervention required")
        showTCCCacheBugInstructions()
    }
    
    private func resetTCCDatabase() -> Bool {
        let task = Process()
        task.launchPath = "/usr/bin/tccutil"
        task.arguments = ["reset", "Accessibility", "com.stt.dictate"]
        
        do {
            try task.run()
            task.waitUntilExit()
            return task.terminationStatus == 0
        } catch {
            NSLog("âš ï¸ Failed to execute tccutil reset: \(error)")
            return false
        }
    }
    
    private func reloadSystemDaemons() {
        NSLog("ğŸ”„ Reloading system preference and TCC daemons...")
        
        let daemons = ["cfprefsd", "tccd"]
        for daemon in daemons {
            let task = Process()
            task.launchPath = "/usr/bin/killall"
            task.arguments = [daemon]
            
            do {
                try task.run()
                task.waitUntilExit()
                NSLog("âœ… Reloaded \(daemon)")
            } catch {
                NSLog("âš ï¸ Failed to reload \(daemon): \(error)")
            }
        }
        
        // Give daemons time to restart
        Thread.sleep(forTimeInterval: 2.0)
    }
    
    private func showTCCCacheBugInstructions() {
        NSLog("")
        NSLog("ğŸ”§ MANUAL TCC CACHE BUG FIX REQUIRED (macOS Sequoia Known Issue)")
        NSLog("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        NSLog("")
        NSLog("ğŸ“ STEP 1: Open System Settings")
        NSLog("   â†’ System Settings > Privacy & Security > Accessibility")
        NSLog("")
        NSLog("ğŸ“ STEP 2: Remove STT Dictate")
        NSLog("   â†’ Find 'STT Dictate' in the list")
        NSLog("   â†’ UNCHECK the checkbox")
        NSLog("   â†’ Click the [-] button to REMOVE completely")
        NSLog("   â†’ Confirm any removal prompts")
        NSLog("")
        NSLog("ğŸ“ STEP 3: Re-add STT Dictate (Critical for cache clearing)")
        NSLog("   â†’ Click the [+] button")
        NSLog("   â†’ Drag '/Applications/STT Dictate.app' into the list")
        NSLog("   â†’ OR browse and select the app")
        NSLog("   â†’ CHECK the checkbox to enable")
        NSLog("")
        NSLog("ğŸ“ STEP 4: Restart STT Dictate")
        NSLog("   â†’ Quit this app completely")
        NSLog("   â†’ Launch from Applications folder")
        NSLog("   â†’ Should see 'âœ… Accessibility granted' in logs")
        NSLog("")
        NSLog("ğŸ¯ This will restore instant AXUIElement text insertion!")
        NSLog("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    }
    
    private func showPermissionInstructions() {
        NSLog("")
        NSLog("ğŸ”§ ACCESSIBILITY PERMISSIONS REQUIRED")
        NSLog("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        NSLog("ğŸ“ System Settings > Privacy & Security > Accessibility")
        NSLog("ğŸ“ Add 'STT Dictate' and enable the checkbox")
        NSLog("ğŸ“ Required for instant text insertion")
        NSLog("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    }
    
    private func checkSystemSettings() {
        print("ğŸ” Checking system settings for Fn key conflicts...")
        
        // Check if Fn key is set to show emoji picker
        let fnUsageType = UserDefaults.standard.object(forKey: "AppleFnUsageType") as? Int ?? 1
        print("ğŸ“‹ Current Fn key setting: \(fnUsageType == 0 ? "Do Nothing" : "Show Emoji & Symbols")")
        
        if fnUsageType != 0 {
            print("âš ï¸  WARNING: Fn key is set to 'Show Emoji & Symbols'")
            print("   Applying Wispr Flow approach - disabling automatically...")
            UserDefaults.standard.set(0, forKey: "AppleFnUsageType")
            UserDefaults.standard.synchronize()
        }
        
        // Apply additional Wispr Flow system optimizations
        print("ğŸ”§ Applying Wispr Flow system optimizations...")
        
        // Force standard F-keys behavior (reduces Fn hooks)
        UserDefaults.standard.set(true, forKey: "com.apple.keyboard.fnState")
        UserDefaults.standard.synchronize()
        
        print("âœ… System settings optimized for Fn interception")
    }
    
    private func setupHotkey() {
        NSLog("âŒ¨ï¸ Setting up Fn key interceptor...")
        
        // Check system settings
        checkSystemSettings()
        
        // Check if we have Input Monitoring permission
        NSLog("ğŸ” Checking Input Monitoring permission...")
        
        // Monitor flagsChanged, keyDown, and keyUp events
        let eventMask = (1 << CGEventType.flagsChanged.rawValue) | (1 << CGEventType.keyDown.rawValue) | (1 << CGEventType.keyUp.rawValue)
        
        // Create callback that captures self
        let selfPtr = Unmanaged.passUnretained(self).toOpaque()
        
        // TARGETED APPROACH: Use default tap but ONLY consume Fn events
        // Safe because we're not using hidutil remapping anymore
        let tapOptions: CGEventTapOptions = .defaultTap
        NSLog("ğŸ“‹ Event tap options: DEFAULT (consume Fn events only)")
        
        eventTap = CGEvent.tapCreate(
            tap: .cghidEventTap,
            place: .headInsertEventTap,
            options: tapOptions,
            eventsOfInterest: CGEventMask(eventMask),
            callback: { (proxy, type, event, userInfo) -> Unmanaged<CGEvent>? in
                guard let userInfo = userInfo else { 
                    print("ğŸš¨ Event callback: userInfo is nil")
                    return Unmanaged.passRetained(event) 
                }
                let service = Unmanaged<VoiceDictationService>.fromOpaque(userInfo).takeUnretainedValue()
                
                // Debug: Log all events to see what we're receiving
                NSLog("ğŸ“¥ Event received: type=\(type.rawValue) (\(type))")
                
                // Set timestamp for Sequoia compatibility (Wispr Flow approach)
                if event.timestamp == 0 {
                    event.timestamp = CGEventTimestamp(mach_absolute_time())
                }
                
                // Handle flagsChanged events (SAFE method for Fn modifier detection)
                if type == .flagsChanged {
                    let currentFlags = event.flags
                    let fnFlag = CGEventFlags.maskSecondaryFn
                    
                    NSLog("   Flags: current=\(currentFlags.rawValue), last=\(service.lastFlags.rawValue)")
                    NSLog("   Fn flag present: \(currentFlags.contains(fnFlag))")
                    
                    // Detect Fn press: Flag set now but not before
                    if currentFlags.contains(fnFlag) && !service.lastFlags.contains(fnFlag) {
                        NSLog("ğŸ”‘ Fn key pressed (flagsChanged) - toggling dictation")
                        
                        // Show visual feedback immediately
                        AppDelegate.shared?.showFnKeyPressed()
                        
                        service.toggleRecording()
                        service.lastFlags = currentFlags
                        
                        // CONSUME Fn event to prevent emoji picker
                        NSLog("ğŸš« Consuming Fn event to prevent emoji picker")
                        return nil
                    }
                    
                    // Update state for next comparison
                    service.lastFlags = currentFlags
                }
                
                // Pass through all non-Fn events (only consume Fn to prevent emoji)
                return Unmanaged.passRetained(event)
            },
            userInfo: selfPtr
        )
        
        if let eventTap = eventTap {
            NSLog("âœ… Event tap created successfully")
            
            let runLoopSource = CFMachPortCreateRunLoopSource(kCFAllocatorDefault, eventTap, 0)
            // CRITICAL FIX: Use main run loop instead of current for app bundles
            CFRunLoopAddSource(CFRunLoopGetMain(), runLoopSource, .commonModes)
            CFRunLoopAddSource(CFRunLoopGetMain(), runLoopSource, .defaultMode)
            NSLog("ğŸ“ Run loop sources added to common and default modes")
            
            // Enable the event tap
            CGEvent.tapEnable(tap: eventTap, enable: true)
            
            // Verify it's enabled
            let isEnabled = CGEvent.tapIsEnabled(tap: eventTap)
            NSLog("âœ… Event tap enabled: \(isEnabled)")
            NSLog("ğŸ” Event mask: \(eventMask) (flagsChanged + keyDown + keyUp)")
            NSLog("ğŸ¯ Ready - Press Fn key to test (will show debug output)")
            
            if !isEnabled {
                NSLog("âš ï¸ WARNING: Event tap is NOT enabled!")
                NSLog("   You may need to grant Input Monitoring permission")
                NSLog("âš ï¸ Please grant Input Monitoring permission to STT Dictate in System Settings")
            }
        } else {
            print("âŒ Failed to create event tap")
            print("âŒ Possible causes:")
            print("   - Missing Accessibility permissions")
            print("   - Missing Input Monitoring permissions (required for Sonoma/Sequoia)")
            print("   - App not in /Applications or not properly code-signed")
            print("   - System security restrictions")
        }
    }
    
    func disableFnTap() {
        if let eventTap = eventTap {
            CGEvent.tapEnable(tap: eventTap, enable: false)
            self.eventTap = nil
            print("ğŸ”Œ Fn key interceptor disabled")
        }
    }
    
    func toggleRecording() {
        NSLog("ğŸ¯ Toggle recording called (currently recording: \(isRecording))")
        
        if isRecording {
            stopRecording()
        } else {
            startRecording()
        }
    }
    
    func isWhisperKitReady() -> Bool {
        let ready = whisperKit != nil
        NSLog("ğŸ” WhisperKit ready check: \(ready ? "READY" : "NOT READY")")
        return ready
    }
    
    func startRecording() {
        guard !isRecording else { 
            NSLog("âš ï¸ Already recording, ignoring start request")
            return 
        }
        
        // Check if WhisperKit is ready
        guard whisperKit != nil else {
            NSLog("âŒ WhisperKit not ready yet")
            NSLog("âš ï¸ WhisperKit is still loading. Please wait a moment and try again.")
            return
        }
        
        NSLog("ğŸ¤ Starting recording process...")
        
        // Check microphone permission status first
        let micStatus = AVCaptureDevice.authorizationStatus(for: .audio)
        
        switch micStatus {
        case .authorized:
            // Already have permission, start immediately
            NSLog("ğŸ¤ Microphone permission already granted")
            DispatchQueue.main.async {
                self.actuallyStartRecording()
            }
            
        case .notDetermined:
            // Need to request permission for the first time
            NSLog("ğŸ¤ Requesting microphone permission...")
            AVCaptureDevice.requestAccess(for: .audio) { [weak self] granted in
                guard let self = self else { return }
                
                DispatchQueue.main.async {
                    if granted {
                        NSLog("ğŸ¤ Microphone permission granted, starting recording...")
                        self.actuallyStartRecording()
                    } else {
                        NSLog("âŒ Microphone permission denied")
                        NSLog("âŒ Please grant microphone access in System Settings")
                    }
                }
            }
            
        case .denied, .restricted:
            // Permission denied or restricted
            NSLog("âŒ Microphone permission denied")
            NSLog("âŒ Please grant microphone access in System Settings > Privacy & Security > Microphone")
            
        @unknown default:
            NSLog("âŒ Unknown microphone permission status")
        }
    }
    
    private func actuallyStartRecording() {
        NSLog("ğŸ¤ Actually starting recording...")
        
        do {
            // Double-check WhisperKit is ready
            guard whisperKit != nil else {
                NSLog("âŒ WhisperKit became nil during recording start")
                throw NSError(domain: "STTError", code: 1, userInfo: [NSLocalizedDescriptionKey: "WhisperKit not ready"])
            }
            
            // Note: No AVAudioSession configuration needed on macOS - handled by AVAudioEngine
            
            isRecording = true
            
            // Update visual feedback
            AppDelegate.shared?.updateRecordingState(isRecording: true)
            
            // Play Apple dictation begin sound
            dictationBeginSound?.play()
            
            bufferQueue.sync {
                audioBuffer.removeAll()
            }
            
            // Reset audio engine if needed
            if audioEngine.isRunning {
                audioEngine.stop()
                NSLog("ğŸ”„ Stopped existing audio engine")
            }
            
            // Reset the audio engine to clear any previous configuration
            audioEngine.reset()
            NSLog("ğŸ”„ Audio engine reset")
            
            let inputNode = audioEngine.inputNode
            NSLog("ğŸ“‹ Input node format: \(inputNode.inputFormat(forBus: 0))")
            
            // Use the input node's native format instead of forcing our own
            let inputFormat = inputNode.inputFormat(forBus: 0)
            
            // Create a compatible format for WhisperKit (16kHz, mono, float32)
            let targetFormat = AVAudioFormat(
                commonFormat: .pcmFormatFloat32,
                sampleRate: sampleRate,  // 16000 Hz for WhisperKit
                channels: 1,
                interleaved: false
            )!
            
            // Remove any existing tap to prevent conflicts (safe even if none exists)
            inputNode.removeTap(onBus: 0)
            NSLog("ğŸ—‘ï¸ Removed any existing audio tap")
            
            // Install tap with input node's native format first
            inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { [weak self] buffer, _ in
                guard let self = self else { return }
                
                // Convert to target format if needed
                if inputFormat.sampleRate != self.sampleRate || inputFormat.channelCount != 1 {
                    // Convert format asynchronously to avoid blocking the audio thread
                    DispatchQueue.global(qos: .userInitiated).async {
                        if let convertedBuffer = self.convertAudioBuffer(buffer, from: inputFormat, to: targetFormat) {
                            self.processAudioBuffer(convertedBuffer)
                        }
                    }
                } else {
                    // Direct processing if formats match
                    self.processAudioBuffer(buffer)
                }
            }
            
            NSLog("âœ… Audio tap installed successfully")
            
            // Prepare and start the audio engine
            NSLog("ğŸ”§ Preparing audio engine...")
            audioEngine.prepare()
            NSLog("âœ… Audio engine prepared")
            
            NSLog("ğŸš€ Starting audio engine...")
            try audioEngine.start()
            NSLog("âœ… Audio engine started successfully - isRunning: \(audioEngine.isRunning)")
            
            NSLog("ğŸ¯ About to start transcription task...")
            startTranscriptionTask()
            NSLog("âœ… Recording started successfully - transcription task created")
            
            // Test if audio tap is actually working
            DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                NSLog("ğŸ“‹ Audio engine status check: isRunning=\(self.audioEngine.isRunning), recording=\(self.isRecording)")
                NSLog("ğŸ“‹ Current audio buffer size: \(self.audioBuffer.count) samples")
            }
            
        } catch {
            NSLog("âŒ Failed to start recording: \(error)")
            isRecording = false
            
            // Clean up on failure
            if audioEngine.isRunning {
                audioEngine.stop()
            }
            
            // Update visual feedback to show error
            AppDelegate.shared?.updateRecordingState(isRecording: false)
            
            NSLog("âŒ Failed to start audio recording: \(error.localizedDescription)")
        }
    }
    
    
    private func convertAudioBuffer(_ buffer: AVAudioPCMBuffer, from inputFormat: AVAudioFormat, to outputFormat: AVAudioFormat) -> AVAudioPCMBuffer? {
        guard let converter = AVAudioConverter(from: inputFormat, to: outputFormat) else {
            NSLog("âŒ Failed to create audio converter")
            return nil
        }
        
        let capacity = AVAudioFrameCount(Double(buffer.frameLength) * outputFormat.sampleRate / inputFormat.sampleRate)
        guard let convertedBuffer = AVAudioPCMBuffer(pcmFormat: outputFormat, frameCapacity: capacity) else {
            NSLog("âŒ Failed to create converted buffer")
            return nil
        }
        
        var error: NSError?
        let status = converter.convert(to: convertedBuffer, error: &error) { _, outStatus in
            outStatus.pointee = .haveData
            return buffer
        }
        
        if status == .error || error != nil {
            NSLog("âŒ Audio conversion failed: \(error?.localizedDescription ?? "Unknown error")")
            return nil
        }
        
        return convertedBuffer
    }
    
    func stopRecording() {
        guard isRecording else { 
            NSLog("âš ï¸ Not recording, ignoring stop request")
            return 
        }
        
        NSLog("ğŸ›‘ Stopping recording...")
        isRecording = false
        
        // Update visual feedback
        AppDelegate.shared?.updateRecordingState(isRecording: false)
        
        // Play Apple dictation confirm sound
        dictationConfirmSound?.play()
        
        // Stop audio engine safely and remove tap
        if audioEngine.isRunning {
            // Remove tap before stopping engine
            audioEngine.inputNode.removeTap(onBus: 0)
            NSLog("ğŸ—‘ï¸ Audio tap removed")
            
            audioEngine.stop()
            NSLog("âœ… Audio engine stopped")
        } else {
            // Even if engine not running, try to remove tap (safe operation)
            audioEngine.inputNode.removeTap(onBus: 0)
            NSLog("ğŸ—‘ï¸ Audio tap removed (engine not running)")
        }
        
        // Cancel recognition task (will interrupt sleep but not transcription)
        recognitionTask?.cancel()
        recognitionTask = nil
        NSLog("âœ… Recognition task cancelled")
        
        // Process any remaining audio in buffer as final chunk
        bufferQueue.sync {
            if !audioBuffer.isEmpty {
                Task {
                    await processChunk()
                    NSLog("âœ… Final audio chunk processed")
                }
            } else {
                NSLog("ğŸ“Š No remaining audio in buffer for final processing")
            }
        }
        
        NSLog("âœ… Recording stopped successfully")
    }
    
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard let channelData = buffer.floatChannelData else { 
            NSLog("âš ï¸ No channel data in audio buffer")
            return 
        }
        
        let channelDataValue = channelData.pointee
        let channelDataValueArray = stride(
            from: 0,
            to: Int(buffer.frameLength),
            by: buffer.stride
        ).map { channelDataValue[$0] }
        
        NSLog("ğŸ¤ Received audio buffer: \(buffer.frameLength) frames, \(channelDataValueArray.count) samples")
        
        bufferQueue.sync {
            audioBuffer.append(contentsOf: channelDataValueArray)
            NSLog("ğŸ“Š Total audio buffer size: \(audioBuffer.count) samples")
        }
    }
    
    private func nonCancellableAsync<T>(_ operation: @escaping () async throws -> T) async throws -> T {
        try await withCheckedThrowingContinuation { continuation in
            Task.detached {
                do {
                    let result = try await operation()
                    continuation.resume(returning: result)
                } catch {
                    continuation.resume(throwing: error)
                }
            }
        }
    }
    
    private func startTranscriptionTask() {
        NSLog("ğŸ¯ Starting transcription task...")
        recognitionTask = Task {
            while isRecording {
                NSLog("ğŸ”„ Processing audio chunk...")
                await processChunk()
                do {
                    try await Task.sleep(nanoseconds: UInt64(chunkDuration * 1_000_000_000))
                } catch {
                    NSLog("ğŸ›‘ Sleep interrupted by cancellation")
                    break  // Exit loop immediately on cancellation
                }
            }
            NSLog("ğŸ›‘ Transcription task ended (isRecording: \(isRecording))")
        }
    }
    
    private func processChunk() async {
        var chunk = bufferQueue.sync {
            let data = audioBuffer
            audioBuffer.removeAll()
            return data
        }
        
        NSLog("ğŸ“Š Audio chunk size: \(chunk.count) samples")
        
        guard !chunk.isEmpty else { 
            NSLog("âš ï¸ Audio chunk is empty - no audio data received")
            return 
        }
        
        // Check if audio is too quiet before processing
        if let maxAbs = chunk.max(by: { abs($0) < abs($1) }) {
            let maxValue = abs(maxAbs)
            NSLog("ğŸ”Š Audio level check: max amplitude = \(maxValue)")
            
            // Apply amplification if audio is very quiet (but not silent)
            if maxValue > 0.001 && maxValue < 0.1 {
                let amplificationFactor: Float = 5.0  // Boost quiet audio
                chunk = chunk.map { $0 * amplificationFactor }
                let newMaxValue = abs(chunk.max(by: { abs($0) < abs($1) }) ?? 0)
                NSLog("ğŸ”Š Applied \(amplificationFactor)x amplification: \(maxValue) â†’ \(newMaxValue)")
            }
            
            // Check for minimum volume threshold
            let finalMaxValue = abs(chunk.max(by: { abs($0) < abs($1) }) ?? 0)
            if finalMaxValue < 0.01 {
                NSLog("âš ï¸ Audio too quiet (max: \(finalMaxValue)) - may not transcribe well")
                NSLog("ğŸ’¡ Try speaking louder or check microphone settings")
            }
            
            // Normalize audio to [-1.0, 1.0] range
            if finalMaxValue > 0 && finalMaxValue < 1.0 {
                chunk = chunk.map { $0 / finalMaxValue }
                NSLog("ğŸ”Š Normalized audio (final max abs: \(finalMaxValue))")
            } else {
                NSLog("ğŸ”Š Audio already normalized or silent (max abs: \(finalMaxValue))")
            }
        }
        
        guard let whisperKit = whisperKit else { 
            NSLog("âŒ WhisperKit is not ready")
            return 
        }
        
        NSLog("ğŸ™ï¸ Sending \(chunk.count) samples to WhisperKit for transcription...")
        
        let transcription: [TranscriptionResult]
        do {
            transcription = try await nonCancellableAsync {
                try await whisperKit.transcribe(
                    audioArray: chunk,
                    decodeOptions: DecodingOptions(
                        task: .transcribe,
                        language: "en",
                        usePrefillPrompt: false,
                        skipSpecialTokens: false, // Allow special tokens for debugging
                        withoutTimestamps: true
                    )
                )
            }
        } catch {
            NSLog("âŒ Transcription error: \(error)")
            return
        }
        
        NSLog("âœ… WhisperKit transcription completed. Results: \(transcription.count)")
        
        // Debug: Full results
        for (index, result) in transcription.enumerated() {
            NSLog("ğŸ“‹ Result \(index): text='\(result.text)', seekTime=\(result.seekTime ?? 0.0)")
        }
        
        if let text = transcription.first?.text {
            let trimmedText = text.trimmingCharacters(in: CharacterSet.whitespacesAndNewlines)
            NSLog("ğŸ” Raw text: '\(text)' (length: \(text.count))")
            NSLog("ğŸ” Trimmed text: '\(trimmedText)' (length: \(trimmedText.count))")
            
            if !trimmedText.isEmpty {
                NSLog("ğŸ“ Transcribed text: '\(trimmedText)'")
                await insertText(trimmedText)
            } else {
                NSLog("âš ï¸ Text is empty after trimming whitespace")
            }
        } else {
            NSLog("âŒ No text in first transcription result")
        }
    }
    
    @MainActor
    private func insertText(_ text: String) async {
        NSLog("âŒ¨ï¸ Inserting text: '\(text)'")
        
        let processedText = processCommands(text)
        NSLog("âŒ¨ï¸ Processed text: '\(processedText)'")
        
        // Wispr Flow approach: Always attempt AXUIElement insertion first
        // This bypasses the macOS Sequoia TCC cache bug where AXIsProcessTrusted() 
        // returns false despite granted permissions
        NSLog("ğŸš€ ATTEMPTING AXUIElement insertion (bypassing TCC cache check)")
        
        if await attemptAXUIElementInsertion(processedText) {
            NSLog("âœ… AXUIElement insertion successful - bypassed TCC cache bug!")
            return
        }
        
        // Traditional permission check for logging
        let permissionGranted = AXIsProcessTrusted()
        if !permissionGranted {
            NSLog("âŒ ACCESSIBILITY DENIED (cached) - AXUIElement failed, using CGEvent fallback")
            NSLog("ğŸ’¡ TIP: If permissions are granted in Settings but this shows denied, restart the app")
        } else {
            NSLog("âš ï¸ AXUIElement failed despite cached permissions - using CGEvent fallback")
        }
        
        NSLog("âš ï¸ Using fallback CGEvent method (slower but works)")
        for char in processedText {
            await insertCharacter(String(char))
        }
    }
    
    @MainActor
    private func attemptAXUIElementInsertion(_ text: String) async -> Bool {
        
        NSLog("ğŸ†• ATTEMPTING AXUIElement text insertion method")
        
        // Get system-wide accessibility element
        NSLog("ğŸ” Creating system-wide AX element...")
        let systemWide = AXUIElementCreateSystemWide()
        NSLog("âœ… System-wide AX element created")
        
        var focusedElement: AnyObject?
        NSLog("ğŸ” Getting focused UI element...")
        let error = AXUIElementCopyAttributeValue(systemWide, kAXFocusedUIElementAttribute as CFString, &focusedElement)
        
        NSLog("ğŸ” AXUIElementCopyAttributeValue result: \(error.rawValue)")
        
        if error != .success {
            NSLog("âŒ Failed to get focused UI element: AXError(\(error.rawValue))")
            
            // Decode the AX error
            switch error {
            case .success: NSLog("   AXError: success")
            case .failure: NSLog("   AXError: failure")
            case .illegalArgument: NSLog("   AXError: illegalArgument")
            case .invalidUIElement: NSLog("   AXError: invalidUIElement")
            case .invalidUIElementObserver: NSLog("   AXError: invalidUIElementObserver")
            case .cannotComplete: NSLog("   AXError: cannotComplete")
            case .attributeUnsupported: NSLog("   AXError: attributeUnsupported")
            case .actionUnsupported: NSLog("   AXError: actionUnsupported")
            case .notificationUnsupported: NSLog("   AXError: notificationUnsupported")
            case .notImplemented: NSLog("   AXError: notImplemented")
            case .notificationAlreadyRegistered: NSLog("   AXError: notificationAlreadyRegistered")
            case .notificationNotRegistered: NSLog("   AXError: notificationNotRegistered")
            case .apiDisabled: NSLog("   AXError: apiDisabled")
            case .noValue: NSLog("   AXError: noValue")
            case .parameterizedAttributeUnsupported: NSLog("   AXError: parameterizedAttributeUnsupported")
            case .notEnoughPrecision: NSLog("   AXError: notEnoughPrecision")
            @unknown default: NSLog("   AXError: unknown(\(error.rawValue))")
            }
            
            NSLog("âš ï¸ AXUIElement failed - returning false for CGEvent fallback")
            return false
        }
        
        guard let focused = focusedElement else {
            NSLog("âŒ No focused element found")
            return false
        }
        
        let focusedUIElement = focused as! AXUIElement
        
        // Check if the element is a text field/area
        var role: AnyObject?
        AXUIElementCopyAttributeValue(focusedUIElement, kAXRoleAttribute as CFString, &role)
        let roleString = role as? String ?? ""
        NSLog("ğŸ” Focused element role: \(roleString)")
        
        // Try to insert regardless of role - some apps have custom roles
        // We'll let it fail gracefully if not editable
        
        // Get current text value
        var currentValue: AnyObject?
        if AXUIElementCopyAttributeValue(focusedUIElement, kAXValueAttribute as CFString, &currentValue) == .success,
           let currentText = currentValue as? String {
            
            // Get selected text range (cursor position if length == 0)
            var rangeValue: AnyObject?
            if AXUIElementCopyAttributeValue(focusedUIElement, kAXSelectedTextRangeAttribute as CFString, &rangeValue) == .success,
               rangeValue != nil {
                let axRange = rangeValue as! AXValue
                if AXValueGetType(axRange) == .cfRange {
                
                var cfRange = CFRange()
                AXValueGetValue(axRange, .cfRange, &cfRange)
                
                let insertLocation = cfRange.location
                let selectionLength = cfRange.length
                
                // Build new text: prefix + inserted + suffix (replace selection if any)
                let textLength = currentText.count
                let safeInsertLocation = min(insertLocation, textLength)
                let safeSuffixStart = min(safeInsertLocation + selectionLength, textLength)
                
                let prefix = String(currentText.prefix(safeInsertLocation))
                let suffix = String(currentText.suffix(from: currentText.index(currentText.startIndex, offsetBy: safeSuffixStart)))
                
                let newText = prefix + text + suffix
                
                // Set new value
                let setError = AXUIElementSetAttributeValue(focusedUIElement, kAXValueAttribute as CFString, newText as CFString)
                if setError != .success {
                    NSLog("âŒ Failed to set new text value: \(setError.rawValue)")
                    return false
                }
                
                // Update cursor position after insertion
                let newCursorLocation = insertLocation + text.count
                var newRange = CFRange(location: newCursorLocation, length: 0)
                if let newAXRange = AXValueCreate(.cfRange, &newRange) {
                    let rangeError = AXUIElementSetAttributeValue(focusedUIElement, kAXSelectedTextRangeAttribute as CFString, newAXRange)
                    if rangeError != .success {
                        NSLog("âš ï¸ Failed to set new cursor position: \(rangeError.rawValue)")
                    }
                }
                
                // Force UI refresh for quirky apps (e.g., Cursor)
                NotificationCenter.default.post(name: NSNotification.Name("NSTextDidChangeNotification"), object: nil)
                
                NSLog("âœ… Text inserted successfully at cursor position with UI refresh")
                return true
                }
            } else {
                // Fallback: Append if range unavailable
                let newText = currentText + text
                let setError = AXUIElementSetAttributeValue(focusedUIElement, kAXValueAttribute as CFString, newText as CFString)
                if setError != .success {
                    NSLog("âŒ Failed to append text: \(setError.rawValue)")
                    return false
                }
                NSLog("âœ… Text appended (cursor range unavailable)")
                return true
            }
        } else {
            NSLog("âŒ Failed to get current text value")
            return false
        }
        
        return false
    }
    
    @MainActor
    private func insertCharacter(_ char: String) async {
        NSLog("ğŸ”¢ OLD METHOD: Inserting character: '\(char)'")
        
        // Create keyDown event
        if let keyDownEvent = createKeyEvent(for: char, keyDown: true) {
            keyDownEvent.post(tap: .cgAnnotatedSessionEventTap)
            NSLog("â¬‡ï¸ KeyDown posted for '\(char)'")
            
            // Small delay between keyDown and keyUp
            try? await Task.sleep(nanoseconds: 5_000_000) // 5ms
            
            // Create keyUp event
            if let keyUpEvent = createKeyEvent(for: char, keyDown: false) {
                keyUpEvent.post(tap: .cgAnnotatedSessionEventTap)
                NSLog("â¬†ï¸ KeyUp posted for '\(char)'")
            } else {
                NSLog("âŒ Failed to create keyUp event for '\(char)'")
            }
            
            // Delay between characters
            try? await Task.sleep(nanoseconds: 15_000_000) // 15ms
        } else {
            NSLog("âŒ Failed to create keyDown event for '\(char)'")
        }
    }
    
    // Helper function to get key codes for common characters
    private func getKeyCode(for char: String) -> CGKeyCode? {
        switch char {
        case "a": return 0x00
        case "s": return 0x01
        case "d": return 0x02
        case "f": return 0x03
        case "h": return 0x04
        case "g": return 0x05
        case "z": return 0x06
        case "x": return 0x07
        case "c": return 0x08
        case "v": return 0x09
        case "b": return 0x0B
        case "q": return 0x0C
        case "w": return 0x0D
        case "e": return 0x0E
        case "r": return 0x0F
        case "y": return 0x10
        case "t": return 0x11
        case "1": return 0x12
        case "2": return 0x13
        case "3": return 0x14
        case "4": return 0x15
        case "6": return 0x16
        case "5": return 0x17
        case "=": return 0x18
        case "9": return 0x19
        case "7": return 0x1A
        case "-": return 0x1B
        case "8": return 0x1C
        case "0": return 0x1D
        case "]": return 0x1E
        case "o": return 0x1F
        case "u": return 0x20
        case "[": return 0x21
        case "i": return 0x22
        case "p": return 0x23
        case "l": return 0x25
        case "j": return 0x26
        case "'": return 0x27
        case "k": return 0x28
        case ";": return 0x29
        case "\\": return 0x2A
        case ",": return 0x2B
        case "/": return 0x2C
        case "n": return 0x2D
        case "m": return 0x2E
        case ".": return 0x2F
        case " ": return 0x31  // Space
        case "\n": return 0x24 // Return
        default: return nil
        }
    }
    
    private func processCommands(_ text: String) -> String {
        var result = text
        
        // Command mappings
        let commands: [(String, String)] = [
            ("new line", "\n"),
            ("new paragraph", "\n\n"),
            ("period", "."),
            ("comma", ","),
            ("question mark", "?"),
            ("exclamation mark", "!"),
            ("colon", ":"),
            ("semicolon", ";"),
            ("open quote", "\""),
            ("close quote", "\""),
            ("open paren", "("),
            ("close paren", ")")
        ]
        
        for (command, replacement) in commands {
            result = result.replacingOccurrences(
                of: command,
                with: replacement,
                options: .caseInsensitive
            )
        }
        
        return result
    }
    
    private func createKeyEvent(for string: String, keyDown: Bool) -> CGEvent? {
        guard let source = CGEventSource(stateID: .hidSystemState) else { 
            NSLog("âŒ Failed to create CGEventSource")
            return nil 
        }
        
        // Handle special characters
        if string == "\n" {
            return CGEvent(keyboardEventSource: source, virtualKey: CGKeyCode(kVK_Return), keyDown: keyDown)
        }
        
        // For regular characters, use Unicode string
        let event = CGEvent(keyboardEventSource: source, virtualKey: 0, keyDown: keyDown)
        let utf16 = Array(string.utf16)
        event?.keyboardSetUnicodeString(stringLength: utf16.count, unicodeString: utf16)
        
        return event
    }
}

